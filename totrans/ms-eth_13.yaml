- en: Machine Learning on the Ethereum Blockchain
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 以太坊区块链上的机器学习
- en: 'Blockchain and AI have been the most interesting topics in recent years for
    a good reason: they are the most advanced technologies that have been created
    to disrupt most established businesses. The fact that we can teach a computer
    to learn by itself is something very powerful, and means that will continue evolving
    the machine learning systems of the future will continue to evolve. Likewise with
    blockchain: the field of distributed computing is just beginning, and it will
    be the default solution for most problems in the future. So why not combine both
    for a revolutionary invention? It turns out that they work nicely together, and
    we can create very interesting dApps that benefit from both worlds, particularly
    by using them to create decentralized marketplaces for solving machine learning
    problems that reward users for their computing power.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 区块链和人工智能是近年来最有趣的话题，这有充分的理由：它们是最先进的技术，已经被创造出来以颠覆大多数已建立的业务。我们能够教会计算机自己学习是一件非常强大的事情，这意味着未来的机器学习系统将继续发展。同样的道理适用于区块链：分布式计算领域刚刚开始，它将成为未来大多数问题的默认解决方案。那么为什么不将两者结合起来进行革命性的发明呢？事实证明它们很好地结合在一起，我们可以创建非常有趣的dApps，从两个领域中受益，特别是通过利用它们来创建分布式市场，以解决机器学习问题，并奖励用户的计算能力。
- en: 'In this chapter, we''re going to cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Understanding machine learning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解机器学习
- en: Decentralized machine learning marketplaces
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式机器学习市场
- en: Building a smart contract machine learning marketplace
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建智能合约机器学习市场
- en: Understanding machine learning
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解机器学习
- en: '**Machine learning** (**ML**) is a subset of **artificial intelligence** (**AI**),
    which in turn is a field in the broader subject of data science. ML is focused
    on creating programs that learn by themselves to solve specific problems without
    having to write all the logic; we just need to give them lots of input. Trial
    and error is the main mechanism with the machine slowly learns how to achieve
    the right output to a problem.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）是**人工智能**（**AI**）的一个子集，而后者又是数据科学更广泛主题中的一个领域。ML专注于创建能够自己学习以解决特定问题的程序，而无需编写所有逻辑；我们只需要给它们大量的输入。试错是主要机制，机器慢慢地学会如何解决问题的正确输出。'
- en: The moment computers were created was the moment scientists asked themselves,
    "How can we make this machine think and act as a human?". That's why understanding
    how computers learn begins with understanding how humans see the world.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机诞生的时刻，科学家们就问自己，“我们如何让这台机器像人类一样思考和行动？”这就是为什么了解计算机如何学习始于了解人类如何看待世界。
- en: 'Think about it for a second: how do you think animals and humans learn to survive
    in the dangerous and confusing world we live in? By learning from others? Well,
    that''s a valid learning system, but all understanding of what we truly know comes
    from experimenting in the face of uncertainty. Imagine the following scenario:
    you are in a primitive world where language hasn''t been invented—we''re talking
    thousands of years ago. You see a flat and shiny red object on the ground that''s
    completely new to you. How do you even begin to understand it? It could be something
    that could kill you or something that could provide you with a new source of materials.
    You don''t know yet, so you begin by trying different things, always with caution,
    since your main goal is to survive. You touch it with a stick: nothing happens.
    You touch it with your hand: it feels warm. You grab it: it feels strong, so you
    try to break it, no success. After some more experimentation, you come to the
    conclusion that what you have in your hands is a strong, naturally formed metallic
    disc that you can use to cook food with the power of the sun.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 想一想：你认为动物和人类如何学会在我们生活的危险而混乱的世界中生存？通过向他人学习吗？嗯，那是一种有效的学习系统，但我们真正了解的一切都来自于在面对不确定性时进行实验。想象一下这样的场景：你处于一个原始世界，语言尚未发明——我们谈论的是数千年前。你在地上看到一个扁平而闪亮的红色物体，这对你来说是完全新的。你如何开始理解它呢？它可能是能够杀死你的东西，也可能是能够为你提供新材料的东西。你还不知道，所以你开始尝试不同的事情，始终保持警惕，因为你的主要目标是生存。你用一根棍子触摸它：没有反应。你用手触摸它：感觉温暖。你抓住它：感觉坚固，于是你试图打破它，没有成功。经过更多的实验，你得出结论：你手里拿着的是一个坚固的、自然形成的金属圆盘，你可以利用它的力量用太阳烹饪食物。
- en: All of that specific knowledge came about from experimentation using the trial-and-error
    mechanism. My point is that this is how we've discovered all of what we know in
    the current world, and it's also the system that machine learning algorithms use
    to solve problems by themselves. You give them lots of information and they experiment
    with their tools, which usually are pixel-by-pixel readings of images and bytes
    of data, to generate an outcome. They are used to predict the future given some
    initial conditions, to understand complex problems that can't be solved with classical
    programming, and to create tools to help us do a better job.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'Technically speaking, there are three steps to create a machine learning system,
    as follows:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Gather lots of information about a topic, such as 2,000,000 images of unique
    water bottles.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Develop a machine learning **model** that generates a desired output. In our
    example, let's say that we want to create a model that classifies water bottles
    based on their shape, size, color, chemical composition, and purity because we
    need to find the best water possible for human use. Those attributes are called
    **labels**, as they are precise descriptions of each component.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The model consumes all that data in a process called **training**, where it
    adjusts how important each component of our water bottles is to calculate which
    factors determine the best water possible. At some point, it will be trained,
    meaning that it will understand what attributes constitute the best water for
    humans, generating a program that we can use to quickly determine how good a specific
    new water bottle is.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That's just an example of how we use machine learning to provide solutions to
    complex questions, such as, what's the best water I can consume for optimal health?,
    What does a dangerous person look like?, How do I teach my camera to determine
    whether what it's seeing is a dog or a cat?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: In general, the steps are getting data -> creating a model that uses that data
    for creating a program -> using the program for specific situations. There are
    many other different systems where the program learns by getting the data by itself
    using trial and error. Other interesting machine learning algorithms work on the
    biological level to teach robots to act as real-life animals, in order to learn
    and see the world like them.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: It's a very hot topic that will continue growing in the coming years to provide
    answers to the most complex problems and questions humans can possibly ask. That's
    why I recommend you explore the vast world of AI. See what's out there before
    combining it with blockchain.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Decentralized machine learning marketplaces
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are going to build a marketplace to buy and sell computing power from users
    that have strong GPUs and want to help others perform machine learning to teach
    their algorithms to complete a task based on supervised learning, where a program
    learns to generate a desired output from a large quantity of input given a goal
    so that it programs itself.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将建立一个市场，用于购买和出售具有强大 GPU 的用户的计算能力，并希望帮助其他人执行机器学习，以教会他们的算法根据监督学习完成任务，其中程序学会根据给定目标从大量输入中生成所需输出，以便自我编程。
- en: Ethereum comes into the equation when we need to deal with storing permanent
    records of the transactions that took place in our ML marketplace along with the
    trained model that the buyer requested from their parameters so that it's accessible
    anytime. The idea is to create a place where people from all around the world
    can start earning money from a new use of their hardware as an alternative to
    mining, while also providing a secure system for ML algorithms.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们需要处理我们的 ML 市场中发生的交易的永久记录以及买家根据其参数请求的训练模型时，以太坊就会介入其中，以便随时可以访问。其理念是创建一个地方，让全世界的人们可以开始通过新的硬件用途来赚钱，作为挖矿的替代方案，同时还提供了一个安全的
    ML 算法系统。
- en: We will use GPUs to train our machine learning programs because they are great
    at processing lots of parallel operations at the same time, so that we can go
    through large batches of input quickly, faster than with a CPU. We'll also use
    Ethereum as the default payment currency to process decentralized transactions
    with ease.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 GPU 来训练我们的机器学习程序，因为它们非常擅长同时处理大量并行操作，这样我们就可以快速处理大批输入，比使用 CPU 更快。我们还将使用以太坊作为默认支付货币，以便轻松处理分散式交易。
- en: 'Most machine learning models nowadays are based on **neural networks** (**NN**),
    which are abstractions of how a human brain works, translated to computers. It''s
    based on virtual individual neurons that receive an input and produce an output
    if a condition is met. For instance, say that a simple neuron contains the following
    statement:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，大多数机器学习模型都是基于**神经网络**（**NN**）的，这是对人脑工作原理的抽象，转化为计算机语言。它基于虚拟的个体神经元，接收输入并在满足条件时产生输出。例如，假设一个简单的神经元包含以下语句：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The statement will return a positive value if the input is larger than 10\.
    That function is what's called an activation function, which makes sense because
    it will activate if the function fulfills the conditions. We can combine many
    of those neurons together with different parameters and configurations to get
    what's known as a neural network, which processes complex input to generate precise
    output. When training, we're readjusting the activation function to better adapt
    to our desired goal. This is all done automatically once it's set up in our model.
    At the end, we get a trained program that is capable of answering complex questions
    without having to code each specific scenario.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果输入大于 10，则该语句将返回一个正值。这个函数被称为激活函数，因为只有在函数满足条件时才会激活。我们可以使用不同的参数和配置将许多这些神经元组合在一起，得到所谓的神经网络，它可以处理复杂的输入以生成精确的输出。在训练时，我们会重新调整激活函数以更好地适应我们的目标。一旦设置好了我们的模型，这一切都会自动完成。最终，我们得到了一个经过训练的程序，能够回答复杂的问题，而无需编写每个特定情景的代码。
- en: 'Once the model is adjusted from our training dataset, we can test it with a
    new input from a different source to determine whether it''s generating an optimal
    output. This is important since there''s a risk of overfitting where the machine
    learning program optimizes too much, becoming too specific to our initial input,
    which makes it unable to produce valid results from new data. It''s like a surgeon
    that has to become a general doctor from scratch: it won''t produce great results
    because it''s too specialized.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型从我们的训练数据集中调整好，我们就可以用来自不同来源的新输入来测试它，以确定它是否生成了最优输出。这很重要，因为存在过拟合的风险，即机器学习程序进行了过多的优化，变得过于特定于我们的初始输入，这样就无法从新数据中产生有效结果。这就像一个必须从头开始成为全科医生的外科医生：它不会产生很好的结果，因为它太专业化了。
- en: Some well-known activation functions are Sigmoid and ReLU. Deep learning is
    the process of stacking several layers of neurons so that the output of a neuron
    is transmitted to another neuron for a more advanced result. These networks are
    known as **deep neural networks** (**DNNs**) because they are made of several
    layers. Make sure to explore the fascinating world of NNs by yourself to learn
    how the technology of the future is being shaped.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一些著名的激活函数是 Sigmoid 和 ReLU。深度学习是将多层神经元堆叠在一起的过程，以便神经元的输出传递到另一个神经元，从而获得更高级的结果。这些网络被称为**深度神经网络**（**DNNs**），因为它们由多层组成。一定要自己探索神奇的神经网络世界，了解未来技术是如何塑造的。
- en: 'We won''t use NNs here as they are hard to implement from scratch on **Solidity**
    because of the limitations of the blockchain, so we''ll work with simpler algorithms
    that you can expand as you need. Here''s how our protocol will work:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们不会使用神经网络，因为由于区块链的限制，从头开始在**Solidity**上实现它们很困难，所以我们将使用您可以根据需要扩展的更简单的算法。这是我们的协议将如何工作的简要说明：
- en: A user publishes a set of data, an evaluation function (our ML model), and the
    reward for completing the task to the smart contract in ETH.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户向智能合约以以太币的形式发布一组数据、一个评估函数（我们的机器学习模型）以及完成任务的奖励。
- en: Those that want to fulfil the task will download the published data from the
    first user to train the given ML model in order to generate a trained program
    that will be given back to the smart contract.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 那些希望完成任务的人将从第一个用户那里下载发布的数据，以训练给定的机器学习模型，以生成一个训练良好的程序，然后将其返回给智能合约。
- en: External users will take a look at all the published solutions for that particular
    task to determine who is the winner. The buyer will determine the winner based
    on their preference.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 外部用户将查看针对该特定任务发布的所有解决方案，以确定谁是赢家。买家将根据自己的偏好确定赢家。
- en: 'From this protocol, we can establish the following process that the users will
    follow:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个协议中，我们可以建立用户将遵循的以下流程：
- en: 'A buyer, someone who wants their model trained, deploys a smart contract that
    contains the following data:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 买家，即想要训练他们的模型的人，部署一个智能合约，其中包含以下数据：
- en: Their model definition in the constructor—for instance, DNN.
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数中的模型定义——例如，DNN。
- en: The datasets to train—for instance, an array of handwritten digit images made
    of 30 x 30 pixels. Each image is an array of 30 x 30 pixels (900 pixels) where
    each pixel is another array containing information about the position of the pixel
    and whether it's black or white (we don't want colors in this image to avoid complexity)—for
    instance [[0, true], [1, false]] will represent a 2 x 1 pixel image where the
    first pixel is black while the other is white. This dataset will be published
    to an external website that people can freely access to train the model. In our
    constructor we will provide a URL, namely `https://example.com/dataset`.
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要训练的数据集——例如，由 30 x 30 像素制成的手写数字图像数组。每个图像都是一个 30 x 30 像素（900 像素）的数组，其中每个像素又是另一个数组，包含有关像素位置以及它是黑色还是白色的信息（我们不希望在这个图像中使用颜色，以避免复杂性）——例如
    [[0, true], [1, false]] 将表示一个 2 x 1 像素的图像，其中第一个像素是黑色，而另一个是白色。这些数据集将发布到一个外部网站，人们可以自由访问以训练模型。在我们的构造函数中，我们将提供一个
    URL，即`https://example.com/dataset`。
- en: The reward for training the model is paid in Ethereum, and this arrangement
    set up in the payable constructor.
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型的奖励以以太坊支付，并在可支付的构造函数中设置了此安排。
- en: The contract is published and sellers begin to participate in the task of training
    the model. From the dataset, 90% of the data will be used to train the model while
    the remaining 10% will be used to test the results from the program to verify
    its accuracy. To make sure sellers don't copy each other, different random datasets
    will be given to different participants.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合约被发布，卖家开始参与训练模型的任务。从数据集中，90%的数据将用于训练模型，而剩下的10%将用于测试程序的结果，以验证其准确性。为了确保卖家不会彼此抄袭，将向不同的参与者提供不同的随机数据集。
- en: The buyer decides which model works best for them and selects a winner. If an
    expiration time is reached and the buyer hasn't selected a winner, the first participant
    will get the reward.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 买家决定哪个模型对他们最有效，并选择一个赢家。如果到达到期时间而买家尚未选择赢家，则第一个参与者将获得奖励。
- en: For our machine learning marketplace, we'll use a simple linear-regression machine
    learning algorithm in Solidity. Users will submit their data, which will contain
    a name and two number parameters to make predictions. A linear regression is a
    relationship between two factors—for instance, the number of sales in a website
    and the number of visitors. In that case, we can establish a model that allows
    us to predict the number of sales for a given number of visitors.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Simple linear-regression models can be applied to many fields where a variable
    depends on another, and it's one of the simplest machine learning systems available.
    That's why we'll be using it, since it's important to be able to recreate it in
    Solidity to verify solutions provided by other users. Ideally, we'd implement
    an NN or a more complex model, but that would take too much time to develop considering
    the limitations of the blockchain. You can build upon the lessons in this chapter
    to extend the marketplace. In the following section, you'll learn how to create
    the code required for the marketplace.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Building a smart contract machine learning marketplace
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our ML marketplace will work with linear regression algorithms exclusively
    to simplify the process so that you understand how it all ties together. I encourage
    you to expand the solution for more advanced models to practice your ML and blockchain
    skills. To apply a simple linear regression algorithm, we need the following things:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: A prediction function to generate a prediction from data
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A cost function to combine the prediction results
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An optimization algorithm to train our algorithm with **gradient descent**,
    which will fine tune the predictions for more precise results
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A train function to improve our algorithm
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The prediction function
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, you need to understand that our simple linear-regression algorithms
    predict values using the following function:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If we are predicting the number of sales based on the number of visitors to
    a website, our prediction function would look like this:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Our goal is to obtain fixed weight and bias values to optimize our prediction
    function so that we get a realistic estimate of sales. For instance, a trained
    linear regression would look like this:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We got a weight of `0.43` and a bias of `0.9` after training from a given dataset.
    We should be able to use that optimized function to make accurate predictions
    for our particular needs with great results. We need to implement the prediction
    function in Python and in Solidity because sellers will use Python to train the
    model, while we''ll use Solidity to verify the result given by those sellers.
    Here''s how our `prediction` function looks in Python and Solidity for our marketplace:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'For your reference, here''s the Solidity function that we''ll add to allow
    sellers and buyers to verify the precision of the model by making predictions:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The cost function
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To train our linear-regression algorithm to generate accurate predictions,
    we need a cost function. A cost function is one way to analyze how well our prediction
    function is working for our dataset. It gives us an error rate, which is essentially
    the difference between the real-world result versus the prediction. The smaller
    the error, the better predictions we''ll make. The cost function takes the real
    result and the prediction to output the error from our model, like so:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要训练我们的线性回归算法以生成准确的预测，我们需要一个成本函数。成本函数是分析我们的预测函数在数据集中工作效果如何的一种方法。它给了我们一个错误率，这实际上是真实结果与预测之间的差异。错误越小，我们做出的预测就越好。成本函数将真实结果和预测作为输入，输出我们模型的错误，如下所示：
- en: '[PRE6]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'There are many different types of cost functions. In our case, we''ll use the
    **mean squared error** (**MSE**) cost function, which looks like this:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，有许多不同类型的成本函数。在这种情况下，我们将使用**均方误差**（**MSE**）成本函数，它看起来像这样：
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To make it clearer, we can add the prediction function with all the parameters
    so that you can see how the variables play our in the cost function, as shown
    in the following code:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使其更清晰，我们可以添加具有所有参数的预测函数，以便您可以看到变量在成本函数中的作用，如下面的代码所示：
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here, `sum()` is the addition of all the real results minus the prediction squared,
    the sum of all the resulting dataset values. All of this is divided by the number
    of data points. Remember that `result` is the actual value that we are trying
    to predict. For instance, going back to our previous example where we are trying
    to predict how many sales we'll get per visitor, the `result` would be `10` sales,
    which comes from 200 visitors, while prediction is our own estimation from the
    weight and bias.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`sum()`是所有真实结果减去预测的平方的总和，所有结果数据集的总和。所有这些都被数据点的数量除以。请记住，`result`是我们试图预测的实际值。例如，回到我们之前的例子，我们试图预测每位访客将获得多少销售额，`result`将是`10`个销售额，这来自200位访客，而预测是我们从权重和偏差得出的估计值。
- en: 'To help you understand the function better, consider the following example
    dataset of fake gun owners in a country and crimes per country; in this example,
    we are interested in learning how the number of guns affects the number of crimes
    per country. Using this data, we can predict crimes so that we can mobilize a
    specific number of police officers to deal with these situations. Remember that
    this is fake data to illustrate how the cost function will work:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您更好地理解该函数，考虑下面的假想数据集的示例：一个国家的假枪支持有和每个国家的犯罪数；在这个例子中，我们有兴趣了解枪支数量如何影响每个国家的犯罪数。利用这些数据，我们可以预测犯罪，以便我们可以调动特定数量的警察来处理这些情况。请记住，这是虚假数据，用来说明成本函数的工作原理：
- en: '| **Country** | **Total number of guns** | **Number of crimes per year** |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| **国家** | **枪支总数** | **每年犯罪数量** |'
- en: '| Germany | 3,520 | 20 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 德国 | 3,520 | 20 |'
- en: '| Estonia | 192 | 3 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 爱沙尼亚 | 192 | 3 |'
- en: '| Bahamas | 91 | 0 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 巴哈马 | 91 | 0 |'
- en: '| Brazil | 9,271 | 88 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 巴西 | 9,271 | 88 |'
- en: 'We first initialize our prediction function with a random weight and bias as
    shown in the following code:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先用随机权重和偏差初始化我们的预测函数，如下所示的代码：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The prediction of crimes for Germany would look like the following:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 德国的犯罪预测如下所示：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We get `352.4` crimes, which we can approximate to 352, since it doesn't make
    sense to talk about crimes in terms of decimal points. As you can see, our prediction
    with that weight and bias is higher than the real result of 20 crimes per year,
    since our model isn't trained yet, so it's normal to expect huge differences what
    using real values.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了`352.4`起犯罪，我们可以近似为352，因为用小数点谈论犯罪没有意义。正如你所看到的，我们使用该权重和偏差的预测比每年20起犯罪的真实结果要高，因为我们的模型尚未训练，所以预计会有巨大的差异。
- en: 'Then we calculate the cost function for all of those values. Let''s see how
    it looks for Germany:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们计算所有这些值的成本函数。让我们看看德国的情况如何：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We are applying the cost function for one data point to see the error of the
    initial prediction so that you can see how it''s applied. Here''s the result:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在将成本函数应用于一个数据点，以查看初始预测的错误，以便您可以看到它是如何应用的。这是结果：
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The error is `110224`, which is a gigantic number, since we are applying it
    to one data point and our model isn't trained yet. Now do the same for all the
    data points until you generate the error for the entire dataset. Hopefully, you
    will understand the process to calculate the error with that example.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 误差为`110224`，这是一个巨大的数字，因为我们将其应用于一个数据点，而且我们的模型尚未训练。现在对所有数据点执行相同操作，直到您为整个数据集生成误差。希望您可以通过该示例了解计算该误差的过程。
- en: 'We need to calculate the error to optimize our prediction function to make
    more accurate predictions later on. Now that the concept is clear, we can implement
    that function in Python. In Solidity, we want it to calculate the error from a
    specific solution for our marketplace in order to discard those that have an excessively
    large error. The `cost` function in Python will be used by the buyers to verify
    the result of their training, and it will be used by sellers in Solidity to verify
    the submissions. Let''s look at the following code:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要计算误差，以优化我们的预测函数，以便稍后进行更准确的预测。现在概念已经清楚，我们可以在 Python 中实现该函数。在 Solidity 中，我们希望它能够从特定市场解决方案计算误差，以便丢弃那些具有过大误差的市场解决方案。Python
    中的`cost`函数将被买家用于验证其训练结果，并且将被 Solidity 中的卖家用于验证提交。让我们看看以下代码：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The `xs` parameter is an array of independent variables, `x`—that we saw in
    the prediction function. Here''s how it looks in Solidity; because it''s a pure
    function, we don''t have to worry about gas costs since everything will be executed
    locally without having to modify the state from the blockchain:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`xs` 参数是独立变量的数组，`x`——我们在预测函数中看到的。在 Solidity 中它看起来是这样的；因为它是一个纯函数，我们不用担心燃气成本，因为一切都将在本地执行，而不必从区块链修改状态：'
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As you can see, we've included the prediction function inside the `for` loop
    to calculate the result minus the prediction squared so that we can calculate
    the error from the `cost` function. This will be used by sellers who want to optimize
    a specific linear regression from a buyer to make accurate predictions.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们将预测函数包含在`for`循环中，以计算结果减去预测的平方，以便我们可以从`cost`函数计算误差。这将由希望优化买家的特定线性回归的卖家使用，以进行准确的预测。
- en: The optimization algorithm
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化算法
- en: 'Now that we can make predictions given some parameters and calculate the precision
    of those predictions with the cost function, we have to work on improving those
    predictions by reducing the error. How do we reduce the error generated from the
    cost function? By adjusting the weight and bias of our prediction function with
    an optimization algorithm. In this case, we''ll use gradient descent, which allows
    us to continuously reduce the error. Here''s a graph that explains how it works:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在给定一些参数的情况下进行预测，并使用成本函数计算这些预测的精度，我们必须努力改进这些预测，通过减小由成本函数生成的误差。我们如何减小成本函数生成的误差？通过使用优化算法调整我们的预测函数的权重和偏差。在这种情况下，我们将使用梯度下降，这使我们能够不断减小误差。以下是说明其工作原理的图表：
- en: '![](img/e8fc70d2-3709-45f9-bf1e-84e0aee20d7e.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e8fc70d2-3709-45f9-bf1e-84e0aee20d7e.png)'
- en: 'We start with a high error caused by random weight and bias values, then we
    reduce the error by optimizing those parameters until we reach a good-enough prediction
    model, the local minimum in the graph. The idea is to calculate the partial derivatives
    of the **weight** and **bias** to see how they affect the final prediction until
    we reach the minimum. We won''t get into the math of calculating those derivatives,
    since it could lead to confusion, so the resulting function with the partial derivatives
    looks like this:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从由随机权重和偏差值引起的高误差开始，然后通过优化这些参数来减小误差，直到我们达到足够好的预测模型，即图表中的局部最小值。想法是计算**权重**和**偏差**的偏导数，看它们如何影响最终预测，直到我们达到最小值。我们不会探讨计算这些偏导数的数学，因为它可能导致混淆，因此带有偏导数的结果函数如下所示：
- en: '[PRE15]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s take a look at the implementation of those functions to update the weight
    and bias of our machine learning algorithm:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看更新机器学习算法的权重和偏差的这些函数的实现：
- en: '[PRE16]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In Solidity, it will look like this:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Solidity 中，它看起来像这样：
- en: '[PRE17]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: As you can see, we are calculating both derivatives by using the functions described
    in the preceding code block so that we can update the weight and bias with the
    optimized values. The learning rate is the size of the steps we take to reach
    the minimum point of the graph. If we take big steps, we may miss the minimum,
    and if we take small steps, we may take too much time to reach that minimum. In
    any case, it's best to keep a balanced learning rate and try different step sizes.
    Now we have a way to improve our prediction function.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们通过使用前面代码块中描述的函数来计算两个导数，以便我们可以使用优化后的值更新权重和偏置。学习速率是我们达到图表最小点的步长大小。如果我们迈出的步子太大，我们可能会错过最小值，如果我们迈出的步子太小，可能需要太长时间才能到达那个最小值。无论如何，最好保持一个平衡的学习速率并尝试不同的步长。现在我们有了改进我们预测函数的方法。
- en: The train function
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练函数
- en: 'We can begin to improve our model with a new function that loops through several
    optimization calls until we reach the minimum, at which point the model will be
    fully optimized. Here''s what it looks like:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以开始通过一个新的函数来改进我们的模型，该函数循环执行多个优化调用，直到达到最小值，此时模型将完全优化。代码如下所示：
- en: '[PRE18]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The Solidity implementation looks pretty similar, although we have to make
    sure that the results and independent variables, values have the same length to
    avoid errors, as shown in the following code:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Solidity 实现看起来非常相似，尽管我们必须确保结果和独立变量的值具有相同的长度，以避免错误，如下面的代码所示：
- en: '[PRE19]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As you can see, we are using the optimization function along with the cost function
    to continuously reduce the error by updating the weight and bias parameters for
    the specified number of iterations.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们正在使用优化函数和成本函数连续减少误差，通过更新权重和偏置参数来进行指定次数的迭代。
- en: Now you should be able to create and train linear regression models to make
    predictions using the prediction function after training your model with the train
    function. The following is the full Python code for your reference, although you
    can see the updated version on the official GitHub at [https://github.com/merlox/machine-learning-ethereum/blob/master/linearRegression.py](https://github.com/merlox/machine-learning-ethereum/blob/master/linearRegression.py).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该能够创建和训练线性回归模型，使用`train`函数训练你的模型后，使用预测函数进行预测。以下是完整的 Python 代码供你参考，尽管你可以在官方
    GitHub 上查看更新版本，链接为[https://github.com/merlox/machine-learning-ethereum/blob/master/linearRegression.py](https://github.com/merlox/machine-learning-ethereum/blob/master/linearRegression.py)。
- en: 'We start by creating the constructor, which will train the model with some
    initial random values using the `uniform` library because it returns a floating
    number between 0 and 1, as shown in the following code:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建构造函数，该构造函数将使用`uniform`库训练模型，并使用初始随机值，因为它返回 0 到 1 之间的浮点数，如下面的代码所示：
- en: '[PRE20]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Then we implement the `prediction` and `cost` function, as you just learned,
    down below the constructor, as shown in the following code:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们实现`prediction`和`cost`函数，就像你刚学的一样，放在构造函数下面，如下面的代码所示：
- en: '[PRE21]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'After that, we add the optimized weights and the bias function, as shown in
    the following code:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们添加了优化的权重和偏置函数，如下面的代码所示：
- en: '[PRE22]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, we complete the code by creating the `train` function and initialize
    the class outside the scope of the class, as shown in the following code:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过在类的作用域之外创建`train`函数并初始化类来完成代码，如下面的代码所示：
- en: '[PRE23]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'As you can see, we''ve created a Python class that runs the `train` function
    in the constructor. Don''t worry if you''re not familiar with Python; you just
    have to understand that the code is training our linear-regression algorithm for
    more precise calculations. Create a file called `linearRegression.py` and write
    the code there. Then you can run it with the following command line:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们创建了一个 Python 类，在构造函数中运行`train`函数。如果你对 Python 不熟悉，不要担心；你只需要理解这段代码正在训练我们的线性回归算法进行更精确的计算。创建一个名为`linearRegression.py`的文件，并将代码写入其中。然后你可以用以下命令行运行它：
- en: '[PRE24]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'You''ll see that the program is constantly reducing the error by taking small
    steps toward the minimum until it gets to a point where it doesn''t improve much.
    That''s okay: we expect it to make precise predictions, but without 100% accuracy.
    You can then take the final weight and bias to make predictions on your own for
    that machine learning model.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到程序不断通过向最小值迈出小步骤来减少误差，直到它达到一个不太改善的程度。这没关系：我们希望它能做出精确的预测，但不一定 100% 准确。然后，你可以用最终的权重和偏置来对那个机器学习模型进行预测。
- en: 'Let''s look at the smart contract marketplace to see how users will interact
    with it. Our goal is to provide a place where machine learning developers can
    upload their model with a payment in Ethereum with the aim of getting the solution
    from several sellers, from which a winner will be selected based on the error
    or the buyer''s choice. Let''s take a look at the following code:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下智能合约市场，看看用户将如何与之交互。我们的目标是提供一个地方，让机器学习开发人员可以上传其模型，并以以太币支付，目的是从几个卖家中获得解决方案，然后根据错误或买家的选择选择一个赢家。让我们看一下以下代码：
- en: '[PRE25]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can start adding variables to create our desired application, as shown in
    the following code:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以开始添加变量来创建我们想要的应用程序，如下所示：
- en: '[PRE26]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We've added three events to notify users that a new job or result has been added,
    as well as when a winner for a proposal is selected. That way, people will be
    notified when their proposal gets updated. Then we have a struct named `Model`,
    which represents our desired linear regression ML model with the dataset, weight,
    bias, and payment, among other important variables. Finally, we've added a couple
    of mappings to sort models created by buyers (those that pay to get their model
    trained) and those models created by sellers, those that train the model from
    the dataset and upload a specific weight and bias in order to win if they are
    selected by the buyer. `latestId` is an identifier to signify which model is the
    latest.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加了三个事件来通知用户已添加了新作业或结果，以及何时选择了提案的获胜者。这样，人们就会在他们的提案被更新时收到通知。然后，我们有一个名为 `Model`
    的结构体，它代表我们希望的线性回归 ML 模型，其中包括数据集、权重、偏差和支付等重要变量。最后，我们添加了一对映射，以对买家创建的模型（那些支付来让他们的模型训练）和卖家创建的模型进行排序，后者训练数据集并上传特定的权重和偏差，以便在被买家选中时赢取。`latestId`
    是一个标识符，表示哪个模型是最新的。
- en: A model that is open means it is still running, so you can send a proposal and
    participate in it for a chance to get selected. If it's closed, you will be able
    to participate, but know that you won't be able to win since the winner has been
    selected already.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 开放的模型意味着它仍在运行，因此您可以发送提案并参与其中，以获得被选中的机会。如果它已关闭，您仍然可以参与，但要知道您将无法获胜，因为获胜者已经被选定。
- en: 'Let''s move on to the three most important functions of our ML marketplace.
    The upload job function looks like the following:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续讨论我们 ML 市场的三个最重要的功能。上传作业功能如下所示：
- en: '[PRE27]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Here''s the upload results function, with some added documentation to clarify
    the parameters used inside:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这是上传结果功能，其中添加了一些文档以澄清内部使用的参数：
- en: '[PRE28]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Finally, here''s the choose results function, which is quite lengthy because
    we must make sure that the job is open and that a winner has not been selected
    yet. If there are no winners selected after three days, the first applicant wins
    the reward to avoid losing Ether:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这是选择结果功能，因为我们必须确保作业是开放的，并且尚未选择赢家，所以这个函数相当冗长。如果三天后没有选择获胜者，第一个申请人将赢得奖励，以避免失去以太币：
- en: '[PRE29]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The `uploadJob` function will be used by buyers to publish their dataset and
    payment in order to get their model trained by participants all over the world.
    The `uploadResult` function will be used by sellers to get information about a
    job to train the specified dataset until the error is minimized. Finally, the
    `chooseResult` function is the one that is used by buyers to select a winner proposal
    for a determined job. The creator of the job has three days to select a winning
    proposal. If after three days no one has applied, then the payment will be returned
    to the owner. If there are participants, but the owner hasn't selected a winner,
    the reward will be sent to the first participant in compensation for their speed;
    in that case, this function has to be executed by an external user to execute
    the payment.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`uploadJob` 函数将由买家使用，以发布他们的数据集和付款，以便让全世界的参与者训练他们的模型。`uploadResult` 函数将由卖家使用，以获取有关训练指定数据集直到错误最小化的作业的信息。最后，`chooseResult`
    函数是由买家用于选择确定作业的赢家提案的函数。作业的创建者有三天的时间选择获胜提案。如果三天后没有人申请，那么支付将退还给所有者。如果有参与者，但所有者尚未选择获胜者，则奖励将作为对速度的补偿发送给第一个参与者；在这种情况下，此函数必须由外部用户执行以执行支付。'
- en: Those are the main components that make our ML marketplace work; however, we
    need a few functions to help people interact with it. Here are the new functions
    that are added to the ML marketplace broken down in pieces to help you understand
    them better.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是构成我们 ML 市场的主要组件；然而，我们需要一些函数来帮助人们与之交互。以下是添加到 ML 市场的新函数，为了更好地帮助您理解，将它们分解成片段。
- en: 'First, we create the cost function with complete documentation so that we can
    understand what it''s doing:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建了完整文档的成本函数，这样我们就能理解它的作用：
- en: '[PRE30]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then we have the get model function to retrieve the variables contained in
    the struct model, because we can''t return the struct as it is right now. We have
    to make these types of tricks to get the struct values independently. This function
    is shown in the following code:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们有获取模型函数来检索结构模型中包含的变量，因为我们目前无法原样返回结构。我们必须做这些类型的技巧来独立获取结构值。以下代码显示了该函数：
- en: '[PRE31]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Then we add another getter function that gives us all the trained models for
    a particular ID, as shown in the following code. This is useful for sellers who
    want to see what proposals they got for their particular job. If we were to implement
    this machine learning marketplace in a dApp, we''d have to add a few more getters
    for the jobs and other mappings:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们添加另一个获取器函数，它为特定 ID 的所有经过训练的模型提供了，如下所示的代码。对于想要查看他们特定作业收到了什么提案的卖家来说，这是很有用的。如果我们要在一个
    dApp 中实现这个机器学习市场，我们将不得不为作业和其他映射添加一些更多的获取器：
- en: '[PRE32]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We have a `cost` function to quickly verify the results uploaded by a proposed
    seller, a `getModel` function that will be mainly used by sellers who want to
    get more specific information about a model, and a `getAllTrainedModels` function
    that returns the participants of a particular job. Note how we're returning the
    most important variables in the struct instead of the entire struct. We are doing
    this for the simple reason that we can't return structs yet in Solidity, so we
    have to separate each variable and return an array for each.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个`cost`函数，用于快速验证由拟议销售方上传的结果，一个`getModel`函数，主要由想要获取有关模型更多具体信息的卖家使用，以及一个`getAllTrainedModels`函数，返回特定工作的参与者。请注意，我们返回结构中最重要的变量而不是整个结构。我们这样做的简单原因是，目前在
    Solidity 中我们无法返回结构，所以我们必须分开每个变量，并为每个变量返回一个数组。
- en: 'The general workflow of this marketplace is as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这个市场的一般工作流程如下：
- en: A buyer with a machine learning model to train uploads their dataset and payment
    to the marketplace with the `uploadJob` function.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拥有要训练的机器学习模型的买家使用`uploadJob`函数将其数据集和付款上传到市场。
- en: An `AddedJob` event gets generated, which notifies users that are interested
    in participating in this marketplace of that new job. They can listen to those
    events by using **web3** or external dApps, since the contract is open source.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成了一个`AddedJob`事件，通知对该市场新工作感兴趣的用户。他们可以使用**web3**或外部 dApps 来监听这些事件，因为合约是开源的。
- en: Sellers read the model data—particularly the timestamps, since that's the most
    important piece of information—with the `getModel` function using the `id` model
    they've received from the event. Then they start training the model using the
    Python application we built earlier or their own, since there are many different
    ways that you can train a linear-regression algorithm.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 卖家使用`getModel`函数读取模型数据，特别是时间戳，因为那是最重要的信息片段，使用他们从事件中收到的`id`模型。然后他们开始使用我们之前构建的
    Python 应用程序或他们自己的应用程序进行模型训练，因为有许多不同的方法可以训练线性回归算法。
- en: They upload their trained weight and bias to that job as a new proposal using
    the `uploadResult` function. This will fire the `AddedResult` event, which will
    notify the buyer whether they're listening to updates so that they can choose
    a winner.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他们使用`uploadResult`函数将他们训练好的权重和偏置上传到该作业作为一个新的提案。这将触发`AddedResult`事件，通知买方是否在听取更新，以便他们可以选择获胜者。
- en: Before three days have passed since the job was created, the buyer goes through
    the proposals, comparing the error generated by each proposal with the `cost`
    function or their own implementation. They'll almost certainly choose the result
    with the smallest error, although they can choose whichever they want. After selecting
    one, the state of the model will change to `isOpen = false`, which means that
    the winner is selected and the `SelectedWinner` event gets fired.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在任务创建后不到三天之内，买家会浏览提案，比较每个提案产生的错误与`cost`函数或他们自己的实现。他们几乎肯定会选择错误最小的结果，尽管他们可以选择任何一个。选择完毕后，模型的状态将变为`isOpen
    = false`，这意味着赢家已选定，并且会触发`SelectedWinner`事件。
- en: That's it! You now are able to upload and train linear-regression models on
    the blockchain.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！您现在能够在区块链上上传和训练线性回归模型了。
- en: Summary
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned the fundamental utility of combining blockchain
    and ML, since they are almost opposites, meaning that they complement each other
    well to create optimal security and performance. We started with a general explanation
    of ML so that you could understand all the hype by taking a quick look at the
    process of generating and training machine learning models. Then we dove deeper
    into the technical functionalities of the application so you got a clear vision
    of where machine learning and blockchain meet. Finally, we built the machine learning
    marketplace, as it's a great combination of both technologies. You saw how the
    linear-regression algorithm works step by step with an implementation in Python
    and Solidity. We built the marketplace, where users from all over the world train
    and exchange computational resources for each task, creating a great secure open
    source platform where people interact without censorship, fees, or centralization.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，您学到了结合区块链和机器学习的基本实用性，因为它们几乎是对立的，这意味着它们互补，可以很好地实现最佳的安全性和性能。我们从机器学习的一般解释开始，这样您就可以通过快速了解生成和训练机器学习模型的过程来理解所有的炒作。然后我们深入探讨了应用的技术功能，这样您就能清楚地看到机器学习和区块链的交汇点。最后，我们建立了机器学习市场，因为这是两种技术的绝佳结合。您看到了线性回归算法如何在Python和Solidity中逐步实现。我们建立了市场，全世界的用户可以在这里为每个任务训练和交换计算资源，创建了一个伟大的安全开放源代码平台，人们在这里可以自由互动，没有审查、费用或中心化。
- en: In the next chapter, we'll explore advanced Ethereum implementations similar
    to what you saw in this chapter, but with different industries, starting with
    a blockchain-based social media platform that combines decentralization with social
    interactions on the internet.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探索类似于本章中所见的高级以太坊实现，但涉及到不同的行业，从一个基于区块链的社交媒体平台开始，它将分散化和互联网上的社交互动结合在一起。
