- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Data Economy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recently, one of the chandeliers at my home got faulty and the electric circuit
    had some weird wiring issues. The bulbs attached to the chandelier started flickering,
    and within an hour or two all the bulbs had fused out following a few dangerous
    sparks. We had to get it fixed, but something else happened as well. My five-year-old,
    who saw it happen mentioned "Appa, this chandelier is losing internet connection,
    see, even the bulbs are not glowing anymore, can we please check the internet?"
  prefs: []
  type: TYPE_NORMAL
- en: I was surprised by the comment, and it made me realize the world we lived in.
    The next generation are so immersed in a world that is seamlessly connected, that
    they might not imagine it ever being otherwise. Such connectivity has its own
    challenges. Connectivity results in interactions, and interactions in turn result
    in data – really big data. Data resulting from these interactions is only valuable,
    however, if it can be sourced, managed, and analyzed efficiently. The connectivity
    that has resulted in the past few years via the internet as a data network has
    now seen a major upgrade. Thanks to Blockchain we now have value networks, where
    connectivity can result in peer-to-peer exchange of value.
  prefs: []
  type: TYPE_NORMAL
- en: This rise in peer-to-peer interactions (be it data or value) has some challenges
    and risks, including cybersecurity, data privacy, and self-sovereign identities.
    Over the years we have seen several firms that have lost or mis-managed customer
    data and have been exposed to reputational and regulatory risks as a result. On
    the same lines, we have seen capital markets prove inadequate in creating inclusive
    value frameworks, allowing the rich to become richer when the poor get poorer.
  prefs: []
  type: TYPE_NORMAL
- en: Emerging technologies such as artificial intelligence, Blockchain, and quantum
    computing can help in managing the new data economy. They can also help the world
    transition into a peer-to-peer value exchange network.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will take you through the advent of the internet, followed by the
    birth of technology firms that built their businesses on top of the internet.
    I describe how this subsequently led to social media and big data, which meant
    that we needed ways to manage the data explosion that followed. The rise of cloud
    and artificial intelligence on such huge volumes of data were logical next steps.
    Using Blockchain to manage data integrity, and quantum computing to better utilize
    data are currently in progress. Let us start with the internet.
  prefs: []
  type: TYPE_NORMAL
- en: The internet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The rise of the internet is well documented across the internet itself. However,
    I feel it would be a good start to understand some of the transitions technology
    has had over the last 50 years in order to get to the data-rich age we live in
    today. The internet was preceded by the invention and the spread of devices like
    transistors, the telephone, radio, and computers. An attempt to connect computers
    to share and broadcast information and collaborate was what led to the internet.
    It all began with the ARPANET.
  prefs: []
  type: TYPE_NORMAL
- en: The ARPANET
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In 1962, J.C.R. Licklider of MIT wrote a series of memos describing the interactions
    that could happen on a network and termed it the **Galactic Network**. The other
    breakthrough in thinking happened when Leonard Kleinrock at MIT, came up with
    the theory that communication using packets instead of circuits was the way forward.
    This inspired the work of Lawrence G. Roberts, who developed the plan for ARPANET
    and published it in 1967\. As a result, in 1969, Kleinrock's Network Measurement
    Center at UCLA hosted the first node on ARPANET. **Stanford Research Institute**
    (**SRI**), UC Santa Barbara and the University of Utah joined the network as subsequent
    nodes. The first message between the hosts happened between Kleinrock's laboratory
    and SRI.
  prefs: []
  type: TYPE_NORMAL
- en: 'ARPANET expanded very quickly as more and more hosts were added to it. However,
    it was only after **Network Control Protocol** (**NCP**) was implemented in 1971-72
    that ARPANET users could develop applications. Using NCP, users could access computers
    remotely and send files. It acted as a transport layer and defined the process
    to connect two computers. Further reading: [https://www.internet-guide.co.uk/NetworkControlProgram.html](https://www.internet-guide.co.uk/NetworkControlProgram.html
    )'
  prefs: []
  type: TYPE_NORMAL
- en: The year 1972 was significant as the first email program was launched where
    users could read, forward, and respond to messages. In the micro-messaging world
    we have today, emails are primarily used in formal communications. In the history
    of the internet, however, email was a critical step.
  prefs: []
  type: TYPE_NORMAL
- en: TCP/IP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ARPANET paved the way for communication within a network using packet switching.
    However, interoperability and connecting to other networks using different technologies
    happened when the **Transmission Control Protocol**/**Internet Protocol** (**TCP**/**IP**)
    was developed by Bob Kahn. TCP/IP as it was called later, has become the bedrock
    protocol for the internet that we use today. TCP/IP is a specification for how
    data interactions happen over the internet and how data should be broken into
    packets, transmitted from the source, and received at the destination. TCP defines
    how application channels can be created over a network (in this case the internet)
    and IP provides an identifier or an address for the packets'' destination. The
    following figure describes the architecture of the internet using TCP/IP:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B13910_08_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: TCP/IP architecture'
  prefs: []
  type: TYPE_NORMAL
- en: The Network Layer is where data gets moved in packets across physical wires,
    cables, or fiber optics. The Internet Layer identifies the host using what we
    call the IP address, and spots the router closest to the destination. The Transport
    Layer is responsible for the end-to-end transfer of data irrespective of the underlying
    network. It also takes care of error handling, flow control, and congestion control
    to avoid a lot of data being sent through the same router. The Application Layer
    covers the protocols that we use for applications like emails, file transfers,
    and websites.
  prefs: []
  type: TYPE_NORMAL
- en: The development and evangelizing of the TCP/IP protocol was a significant phase
    in the evolution of the internet. ARPANET subsequently moved from NCP to TCP/IP
    after a few years of planning, and the transition was surprisingly smooth.
  prefs: []
  type: TYPE_NORMAL
- en: In 1989, a British scientist called Tim Berners-Lee came up with the concept
    of the **World Wide Web**. This meant **Uniform Resource Locators** (**URL**)
    could be a space to hold information. These URLs could be interlinked and accessed
    using the internet. By 1990, Tim also came up with **HyperText Markup Language**
    (**HTML**), the language that was the bedrock of the web.
  prefs: []
  type: TYPE_NORMAL
- en: The boom, the bust, and the boom
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Several firms incorporated the TCP/IP protocol through the 1980s. However, it
    was only in the 1990s that the mainstream adoption of the internet took place.
    Several internet-based businesses started to shape up through the 1990s, and personal
    computers started to become common place. As the convergence of these two innovations
    (the internet and PCs) happened through the mid-90s, there was a boom in the internet
    market. Several firms saw a growth of about 500% in two years' time. For example,
    **AOL** (**America Online**) grew from $70 million at IPO in 1992 to over $150
    billion in early 2000.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks to the irrational exuberance of the late 90s, the **Venture Capital**
    (**VC**) industry splurged money into start-ups at will. Valuation models used
    by these VCs to assess investment opportunities were fundamentally flawed, and
    in many cases there were no valuation exercises performed. Several firms without
    sound business models got funding at crazy valuations, resulting in a bubble and
    a bust (described as follows). This is a classic example of how history repeated
    itself, as the dot net bubble repeated itself, though at a smaller scale, with
    the Blockchain/cryptocurrency industry in late 2017/2018\. Key events through
    this boom and bust can be timelined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Boom**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Aug 1995: Netscape began trading, marking the launch of the internet era'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Apr 1996: Yahoo went public and saw a doubling up of share price on day 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'May 1997: Amazon went public and saw a 30% increase in share price on day 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jan 1998: NASDAQ opened the year at 1574.10, registering a two-year gain of 50%'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sep 1998: Google was founded by Larry Page and Sergey Brin'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sep 1998: eBay went public and its share price closed at 163% on the opening
    day'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mar 2000: NASDAQ hit a peak of 5132.52'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Bust**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mar 2000: Three days after its peak, NASDAQ lost 4.5%'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Apr 2000: NASDAQ lost 25% of its value in a week and the bubble had burst'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dec 2000: eBay shares traded at a low of $2.81 (the first day close was at
    $47.35)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dec 2000: NASDAQ ended the year at 2470.52, a 52% loss from its peak in March'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mar 2001: eToys shares were worthless. The firm exhausted $800 Million in three
    years and filed for bankruptcy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'April 2001: TheGlobe.com shares slipped below $1.00, and got delisted from
    NASDAQ'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nov 2001: Amazon shares hit a low of $5.51'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Recovery**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Q1 2003: Amazon reported its first annual profits of $35 million'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aug 2004: Google went public and its shares rose 18% on the opening day'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As the sun set on the internet empire in the early 2000s, most firms lost value
    within weeks. Many firms went bankrupt and investors lost their capital. However,
    after a painful few years the dust settled. Several of the other internet/technology
    companies recovered from the dot com bubble burst. However, it was a slow process.
    Microsoft shares didn't get back to their highs of December 1999 until October
    2016\. The popping of the dot com bubble identified firms that went on to define
    the future of computers and the internet. The survivors of the dot come bubble
    went on to build the framework for what we know today as social media.
  prefs: []
  type: TYPE_NORMAL
- en: Social media
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The internet revolution was followed by yet another technology paradigm – social
    media. While the internet was about connecting people and sharing information,
    the information that was available to be utilized was still limited (relatively).
  prefs: []
  type: TYPE_NORMAL
- en: Social media created interactions, blogging, and micro-blogging opportunities,
    leading to a data explosion.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B13910_08_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Social media applications'
  prefs: []
  type: TYPE_NORMAL
- en: As social media took the world by storm, there were a few key developments with
    big technology firms. Facebook spotted early winners in Instagram and WhatsApp.
    While Instagram was a steal at $1 billion, the acquisition of WhatsApp at $19
    billion did raise some eyebrows. The size of the market that these applications
    were addressing, however, justified the cost. Also, by the time WhatsApp was acquired
    in 2014, Facebook's revenue in advertisements alone was about $12 billion, and
    the user base was at 1.3 billion people.
  prefs: []
  type: TYPE_NORMAL
- en: Despite the success of Facebook's revenue model, they were clear that they had
    to expand their user base globally. Their ambition was to have every internet
    user as a customer, and where internet penetration was poor, they even strategized
    ways to provide the internet. The race for user data was on, and as they offered
    their services free, their users were their commodity.
  prefs: []
  type: TYPE_NORMAL
- en: Let us touch upon the size of the market and the amount of data created using
    these social media applications. This will help us understand why the emerging
    technologies that are covered in this chapter are relevant now more than ever
    before. These numbers will shed light on why the big technology firms were focusing on
    growing their customer base.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some numbers to note are (as of January 2019):'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 billion people use the internet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3.4 billion people actively use social media
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Facebook and WhatsApp create 60 billion messages a day
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 45 billion WeChat messages were sent in 2018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 46 TB of data is consumed on WeChat during 1 minute of the morning rush hour
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google has answered 450 billion unique queries since 2003
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 300 hours of video are uploaded to YouTube every minute
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can clearly see the monstrous growth of data in the world based on the preceding
    statistics. Much of this growth has been driven by the widespread adoption of
    social media by users across the world.
  prefs: []
  type: TYPE_NORMAL
- en: '"There were 5 exabytes of information created by the entire world between the
    dawn of civilization and 2003\. Now that same amount is created every two days."'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: – *Eric Schmidt, Ex-CEO and Chairman of Google in 2010*
  prefs: []
  type: TYPE_NORMAL
- en: This data has been used by the tech-giants over the years for various commercial
    purposes. This has also led to a backlash from governments, regulators, and even
    customers on data privacy rights. The scandal where Facebook shared data on 87
    Million people with Cambridge Analytica created a lot of reputational issues for
    the firm and highlighted the need for better data controls and regulations. The
    tag **#FacebookIsDead** started trending, and many millennials and Generation
    Z users moved away from the social media giant due to their treatment of user
    data. It was clear that data regulations, governance, and controls were mandatory.
    But before moving on to that, let us first look at how firms managed this big
    explosion of data using big data technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Big data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The term **Big data** was coined by Roger Mougalas in 2005, a year after Web
    2.0 was coined. Web 2.0 was used to indicate the data era where traditional business
    intelligence tools were ineffective due to the size of the data they had to deal
    with. The same year, Yahoo developed Hadoop on Google's MapReduce with an ambition to
    index the **World Wide Web**. Hadoop is an open source framework that can handle
    both structured and unstructured data.
  prefs: []
  type: TYPE_NORMAL
- en: Structured data is identified by well-defined data types, data rules, and controls
    that they would adhere to. Structured data typically sits in databases where the
    exact parameters of data are predefined. Oracle, Microsoft SQL Server, and several
    other database management systems were very focused on dealing with structured
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Unstructured data does not have the same level of structural discipline, primarily
    because of the way it is generated. Unstructured data comes in all shapes and
    forms most of the data that exists in the world today. It could be data generated
    from social media, emails, chats, voice recordings, and videos. Social media necessitated
    the efficient management of unstructured data and several technologies started
    to emerge to address this opportunity.
  prefs: []
  type: TYPE_NORMAL
- en: Another classification of databases is relational and non-relational. Relational
    databases like MySQL, Microsoft SQL Server, and Oracle store data in a structured
    format within tables. These tables can be linked to each other through relationships.
    These relationships make sure the integrity of data is intact.
  prefs: []
  type: TYPE_NORMAL
- en: However, the downside of this model is that, it takes a lot of time to transform
    data into a relational schema. Therefore, it may not be the best option when data
    volumes are huge, and processing is often expected to be in a fraction of a second.
    Extracting data from a relational database is typically done using **Structured
    Query Language** (**SQL**).
  prefs: []
  type: TYPE_NORMAL
- en: Non-relational databases like MongoDB, Neo4J, and Cassandra store data in formats
    such as JSON or XML. They come in handy when data consistency is less important,
    and availability and query response times need to be more important. These databases
    also allow for horizontal scaling more seamlessly. This is important when large
    data volumes are involved.
  prefs: []
  type: TYPE_NORMAL
- en: Before getting into the depths of how big data management happens, it would
    first be useful to understand how structured data is sourced, managed, and analyzed.
  prefs: []
  type: TYPE_NORMAL
- en: Structured data processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In a traditional environment where data sticks to well-defined data types,
    the process of sourcing, preparing, managing, and delivering them in a format
    suitable for reporting and analytics involves a process called **ETL** – **Extract**,
    **Transform**, and **Load**. The system where all these processes happen in an
    organization is called a **data warehouse**. We''ll briefly discuss each of these
    processes, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Extract**'
  prefs: []
  type: TYPE_NORMAL
- en: Data is sourced from across the organization in various forms and stored in
    tables in a database called the staging database. The sources could be flat files,
    a messaging bus, or a transaction database that is highly normalized for quick
    transaction writes. Source to target mappings are pre-defined to ensure that the
    source data was delivered to the staging area in a compatible structure (data
    type). The tables in the staging database act as the landing area for this data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Transform**'
  prefs: []
  type: TYPE_NORMAL
- en: Data in staging tables goes through transformations that are predefined. These
    transformations are identified well ahead of time and coded into the system. Where data
    is identified as incompatible with these transformations and the rules set within
    the system (data types, logical criteria), the data is logged into an error-handling
    queue.
  prefs: []
  type: TYPE_NORMAL
- en: '**Load**'
  prefs: []
  type: TYPE_NORMAL
- en: Transformed data is then loaded into the data warehouse, and by this time it
    is generally high quality. This final database could also be a data mart, which
    is often a miniature data warehouse satisfying a specific purpose or part of an
    organization. In any case, there are several hops that data needs to take before
    getting to a shape where it is ready for analysis and reporting.
  prefs: []
  type: TYPE_NORMAL
- en: This process used to work in a conventional setup. However, it may not be practically
    possible to find a place to store 2.5 quintillion bytes of data (the data created
    per day) that do not stick to the semantic limitations of a structured database.
    Hence the need for a shift in approach using big data platforms. Let us now look
    at how unstructured data management has addressed some of the challenges posed
    by the data era.
  prefs: []
  type: TYPE_NORMAL
- en: Unstructured data processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Conventional database management systems are not designed to deal with the
    volume of data and lack of structure often associated with the internet. The key
    components of a big data system include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data sources**'
  prefs: []
  type: TYPE_NORMAL
- en: Data sources in a big data system can be text files, messages from social media,
    web pages, emails, audio files, and video files. With the rise of the **Internet
    of Things** (**IoT**), data generated by the interactions of machines would also
    be a source that big data systems need to deal with.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data storage**/**Data lake**'
  prefs: []
  type: TYPE_NORMAL
- en: Data from these sources are stored in a distributed file store system like the
    **Hadoop Distributed File System** (**HDFS**). The distributed nature of the store
    allows it to deal with high volumes and big data sizes. Data lakes can also deal
    with structured data, but do not need data to be in a structure.
  prefs: []
  type: TYPE_NORMAL
- en: Firms that successfully implemented a data lake have outperformed competition
    by 9% in organic revenue growth (as per research by Aberdeen)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Source: [https://s3-ap-southeast-1.amazonaws.com/mktg-apac/Big+Data+Refresh+Q4+Campaign/Aberdeen+Research+-+Angling+for+Insights+in+Today''s+Data+Lake.pdf](https://s3-ap-southeast-1.amazonaws.com/mktg-apac/Big+Data+Refresh+Q4+Campaign/Aberdeen+Research+-+Angling+for+Insights+in+Today''s+Data+Lake.pdf
    )'
  prefs: []
  type: TYPE_NORMAL
- en: Unlike a traditional data warehouse, data lakes get a schema at read time.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data processing**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Data processing in a big data infrastructure could happen in different ways
    depending on the nature of data fed into the system:'
  prefs: []
  type: TYPE_NORMAL
- en: Batch processing is typically used to process large files. These batch jobs
    process incoming files and store the processed data in another file. Tools like Hive,
    Pig, or MapReduce jobs can address this type of processing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Real-time data processing happens in a system where data is from social media
    or IoT devices as a continuous flow of data needs to be handled. This data flow
    is captured in real time, and this could also involve using a message buffer to
    deal with the real-time volumes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This data can then be transformed using conventional techniques and moved into
    an analytics database/data warehouse.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alternatively, where the conventional process is not preferred, a low-latency NoSQL
    layer can be built on top of the data files for analytics and reporting purposes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let us now look at different architectures that have been explored to manage
    big data.
  prefs: []
  type: TYPE_NORMAL
- en: Big data architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are big data architectures that address both the handling of high-volume
    data and accurate analytics requirements. For instance, the Lambda architecture
    has a hot path and a cold path. The hot path handles high volumes of data coming
    in from sources like social media, however, for read operations, the hot path
    provides quick access with lower data accuracy. On the other hand, the cold path
    involves a batch process that is time-intensive, but processes data to provide
    highly accurate analytics capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: The hot path typically holds data only for a short period of time, after which,
    better quality data processed from the cold path replaces this data. The Kappa
    architecture took inspiration from the Lambda architecture and simplified it by
    using a stream processing mechanism and just using one path against the Lambda
    architecture's two. This takes away the complexity of duplication and ensuring
    the convergence of data. Frameworks like Apache Spark Streaming, Flink, and Beam
    are able to provide both real-time and batch processing abilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'The third architecture used by big data systems is the Zeta architecture. It
    uses seven pluggable components to increase resource utilization and efficiency.
    The components are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Distributed file system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Real-time data storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pluggable compute model / Execution engine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment / Container management system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solution architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enterprise applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dynamic and Global resource management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The benefits of this architecture include:'
  prefs: []
  type: TYPE_NORMAL
- en: Reducing complexity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding data duplication
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing deployment and maintenance costs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improving resource utilization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breaking down the solution into reusable components adds efficiencies across
    several aspects of developing and managing a big data platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'While the architectures are interesting to understand the maturity of the technology,
    the outcomes are perhaps more important. For instance, big data systems have allowed
    for better use of data captured in the form of social media interactions. The maturity
    of infrastructure to handle big volumes of data has helped clever customer-specific
    services provided across several industries. Some of the common use cases we have
    seen using social media analytics for example are:'
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis for brands
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brands can use social media analytics to understand sentiments about their brands
    or recent launches and tweak their offerings accordingly.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer segmentation and targeted advertisements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Several social media platforms provide details on exactly where organizations
    were getting the biggest bang for their buck on marketing. Firms can fine-tune
    their marketing strategies based on this information and reduce cost of acquisition
    of customers.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Proactive customer services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gone are the days when customers had to go through a cumbersome complaints process.
    There are several instances where customers have logged their complaints about
    a particular experience on Twitter or Facebook, and the brands have acted immediately.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Political campaigns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even political campaigns before elections are managed proactively using social
    media insights. The West is perhaps more used to such activities, but in India
    for example, Prime Minister Narendra Modi has managed to capture the attention
    of his followers using clever social media tactics.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Several Asian political organizations have been accused of releasing fake news
    during a political campaign to mislead voters. For instance, WhatsApp was used
    as a platform to spread fake news about the India-Pakistan air battles just before
    the 2019 Indian elections. The Brexit referendum in 2016 is another example where
    parties were accused of voter manipulation. Source: [https://www.bbc.com/news/world-asia-india-47797151](https://www.bbc.com/news/world-asia-india-47797151
    )'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: There are several other ways in which organizations use social media data for
    continuous consumer engagement. For instance, understanding sentiments of users,
    proactively managing complaints, and creating campaigns to increase brand awareness
    can all be done on social media.
  prefs: []
  type: TYPE_NORMAL
- en: As an investor, when I assess firms, one of the key dimensions I take into consideration
    is their awareness and ability to drive brand awareness, customer acquisition,
    and continuous engagement through social media channels. Understanding the advantages
    of using social media effectively has become a basic attribute to running a business.
    It is no longer just an option. The rise of social media saw firms move from on-premise
    servers to cloud-based infrastructure. There may not be a causation, but there
    definitely is a correlation between social media and the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: The cloud
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Big data frameworks that architecturally catalyzed the big data revolution were
    also supported by the evolution of cloud computing in parallel. Without these
    technology paradigms going mainstream, it would not have been possible to capture, store,
    and manage large volumes of data. It all started in 2002, when Amazon launched
    its online retail services. They had to procure massive servers to manage the
    Christmas season peak in traffic. At other times, the utilization of their servers
    was about 10%, and that was commonplace in those days.
  prefs: []
  type: TYPE_NORMAL
- en: The team at Amazon identified the underutilization patterns of their servers
    and felt that they could create a model to improve utilization during non-peak
    times. Sharing their server infrastructure with others who needed server resources
    could add efficiencies for everyone. The concept of cloud infrastructure was born.
  prefs: []
  type: TYPE_NORMAL
- en: Jeff Bezos and his team of executives eventually decided to make the most of
    the unused server capacity during non-peak times. Within a year, the team at Amazon
    had put together a service that offered computer storage, processing power, and
    a database. This business model transformed the innovation landscape as server
    infrastructure became more affordable for startups.
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon Web Service** (**AWS**) went live in 2006 and by 2018 it was a $26
    billion revenue-generating machine. Google, Microsoft, IBM, and others followed
    suit; however, Amazon have clearly got their nose ahead. 80% of enterprises were
    both running apps on or experimenting with AWS as their preferred cloud platform
    by 2018 (as per Statista). The cost of starting a business has plummeted since
    the mainstream adoption of cloud services.'
  prefs: []
  type: TYPE_NORMAL
- en: Procuring infrastructure on a need basis has also made it cost-efficient to
    run and scale businesses.
  prefs: []
  type: TYPE_NORMAL
- en: '![uncaptioned image](img/B13910_08_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Planned and current use of public cloud platform services worldwide,
    2018\. Source: https://www.statista.com/statistics/511467/worldwide-survey-public-coud-services-running-application/'
  prefs: []
  type: TYPE_NORMAL
- en: As cloud services matured and scaled, several new models emerged, namely, **Software
    as a service** (**SaaS**), **Platform as a service** (**PaaS**), and **Infrastructure
    as a service** (**IaaS**).
  prefs: []
  type: TYPE_NORMAL
- en: SaaS is a model in which a software application is virtually managed on a server
    by a vendor and accessed by users over the internet. Google Docs was one of the
    early examples of this model. Today, we use cloud-hosted SaaS for several day
    to day applications for the simplest of tasks, from document management to conducting
    teleconferences. Thanks to this model, our laptops do not cry out for software
    updates on applications every other minute. However, we have also become increasingly
    reliant on the internet and feel dysfunctional without it.
  prefs: []
  type: TYPE_NORMAL
- en: PaaS is a model where instead of providing an application over the internet,
    the vendor provides a platform for developers to create an application. For instance,
    many vendors offer Blockchain in a PaaS model, where developers can use cloud-managed
    software development services to create Blockchain applications. IBM offers a
    similar service for quantum computing too, however, that can also be bucketed
    into the IaaS model.
  prefs: []
  type: TYPE_NORMAL
- en: IaaS is a model where computer resources are offered as a service. This would
    include server storage, computing and networking capacity, disaster recovery,
    and many others. This has helped large organizations to reduce their infrastructure
    footprint by moving to the cloud. Data centers were migrated to the cloud, hence
    achieving efficiencies across computer resources, but also reducing their carbon
    footprint.
  prefs: []
  type: TYPE_NORMAL
- en: With these advances in architectural, software, and infrastructure technology
    paradigms, the data age had well and truly taken off. We had figured out ways
    of creating and managing data at scale. However, what we weren't very good at
    was exploiting data volumes to develop intelligence at scale – intelligence that
    could challenge humans. Enter AI.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial intelligence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I mentioned AI as if it was actually developed for the first time after the
    social media explosion. Nothing could be further from the truth; AI has been conceptually
    around for a long time. The concept of robots behaving like humans was introduced
    in science fiction in the early 20^(th) century. Yet, it only started to become
    a serious field of research from 1950, when Alan Turing posed the question,
  prefs: []
  type: TYPE_NORMAL
- en: '**"Can Machines Think?"**'
  prefs: []
  type: TYPE_NORMAL
- en: Origins of AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As Alan Turing started exploring that question, he came against not only mathematical
    challenges, but also theological objections. He refuted the argument that God
    had given an immortal soul to humans, but not to any other animal or to machines,
    hence no animal or machines could think.
  prefs: []
  type: TYPE_NORMAL
- en: He made it clear that, in attempting to make machines think, we (the society
    and humans) were not standing against God's will. He argued that it wasn't the
    first time theology and science would take seemingly contradicting positions.
  prefs: []
  type: TYPE_NORMAL
- en: He pointed out that the Copernican theory disagreed with the biblical verse
    below. Copernicus had proposed that the sun was the center of the universe and
    the earth and the other planets revolved around it.
  prefs: []
  type: TYPE_NORMAL
- en: '"He laid the foundations of the earth, that it should not move at any time"
    (Psalm 104:5)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Alan Turing also laid out his views of the future for thinking machines.
  prefs: []
  type: TYPE_NORMAL
- en: '"I believe that in about fifty years'' time it will be possible, to program
    computers, with a storage capacity of about 10⁹, to make them play the imitation
    game so well that an average interrogator will not have more than 70 per cent
    chance of making the right identification after five minutes of questioning. The
    original question, "Can machines think?" I believe to be too meaningless to deserve
    discussion. Nevertheless, I believe that at the end of the century the use of
    words and general educated opinion will have altered so much that one will be
    able to speak of machines thinking without expecting to be contradicted.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I believe further that no useful purpose is served by concealing these beliefs.
    The popular view that scientists proceed inexorably from well-established fact
    to well-established fact, never being influenced by any improved conjecture, is
    quite mistaken. Provided it is made clear which are proved facts, and which are
    conjectures, no harm can result. Conjectures are of great importance since they
    suggest useful lines of research."
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The practical challenges of even attempting AI experiments were huge in those
    days. Computational power and data storage capacity (or lack the thereof) were
    the largest bottlenecks. Computers not only had to store words, but also needed
    to understand the relationships between them in order to conduct meaningful communication.
  prefs: []
  type: TYPE_NORMAL
- en: There were scientists and researchers who were bullish that machines would have
    the general intelligence of a human being. They came up with different timelines
    for "**AI Singularity**." Despite AI winters when the technology was viewed as
    hype, the research community made consistent progress; in the 1980s the concepts
    of deep learning were introduced by John Hopfield and David Rumelhart, and the
    field of AI started to get a new boost through a surge in research funding.
  prefs: []
  type: TYPE_NORMAL
- en: The first practical breakthrough perhaps happened in 1996 when grandmaster Gary
    Kasparov was defeated by IBM's Deep Blue in a game of chess. Deep Blue was a computer
    program, and the result of the game was hugely publicized and was considered a
    big breakthrough in the field at that time. Around the same time, Microsoft integrated
    a speech recognition software developed by Dragon Systems into its Windows operating
    system.
  prefs: []
  type: TYPE_NORMAL
- en: The scientific community had realized that AI was not just a program that miraculously
    behaved like a human. It was an approach that used algorithms built using high
    volumes of good-quality data. This allowed algorithms to get a better understanding
    of the context in which the machine was operating in, and provide relevant answers
    as outputs.
  prefs: []
  type: TYPE_NORMAL
- en: The imitation game
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another contribution from Turing was the Turing test. The test was called *The
    Imitation Game*. The game was constructed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: There were three rooms, each connected through computer screens and keyboards
    to the others.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the first room sat a human, in the second a computer, and in the third a
    "judge."
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The judge's job was to identify (through five minutes of interaction) the human and
    the machine based on their responses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Turing proposed that if the judge were less than 50% accurate in identifying
    the human or the machine, it meant that the judge was as likely to pick either the
    human or the computer. That made the computer a passable simulation of a human
    being and intelligent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Over the years, there were several simplifications of this experiment that programmers
    used as a litmus test for the intelligence of their solutions. Some subsequent
    researchers have criticized the ability of the Turing test in identifying genuinely
    intelligent systems, whilst other papers have been written in defense of the test.
    Irrespective of that, the contribution of Alan Turing to the field of Artificial
    Intelligence is no doubt immense. He was the visionary who sowed seeds for future generations
    to reap the benefits.
  prefs: []
  type: TYPE_NORMAL
- en: Avatars of AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I often find people using AI interchangeably across many of the more detailed
    branches of AI listed out in *Figure 4*. Oftentimes, using **AI** to refer to
    a machine learning solution gets challenged. The way I see it is that these sub-clusters
    of AI focus on leveraging data to make better decisions. In some scenarios this
    intelligence augments humans, and sometimes machines make the decisions themselves
    and learn from them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithmic details of AI, like Neural Networks, clustering, and Bayesian
    networks are all covered as techniques under branches of AI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B13910_08_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Branches of AI'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning is perhaps the most common form, where patterns are recognized
    in data and predictions are made using these patterns. The pattern recognition
    process involves feeding a lot of data to algorithms, and developing the solution
    to learn with this training data. After the machine has learned from the training
    data, it is used to apply the learning to a new set of data. If the new set of
    data exhibits similar patterns to the training data, then the machine highlights
    them. Therefore, the breadth and the quality of the training data is very critical
    in the learning process. Let me explain this with an example I was involved in.
  prefs: []
  type: TYPE_NORMAL
- en: I had the privilege of sitting on the IBM Watson evaluation board, when I was
    at PwC in 2014\. We were evaluating the feasibility of using IBM Watson for regulatory
    solutions. Since 2008, the financial regulators of the UK and EU had come up with
    several complex regulations, and banks were expected to understand volumes of
    regulatory text and ensure compliance. Thousands of lines of complex regulatory
    text to cover, with complementary and conflicting regulatory rules and frequently
    changing regulations all made it very hard for the banks to stay on top of their
    regulatory obligations.
  prefs: []
  type: TYPE_NORMAL
- en: The IBM Watson solution that we were evaluating would take all the regulatory
    texts (in legal language) as inputs. We would also provide as inputs natural language versions
    of those regulatory texts (where available). Two regulatory experts would work
    with IBM Watson, and in what they called the "*Watson going to School*" process,
    the AI engine would get trained in the regulations. The experts would ask the
    AI a question regarding a regulation, and when the answer was provided, the experts
    would give a thumbs up or thumbs down, depending on the quality of the answer.
    This helped the AI engine learn over time and get better at answering simple,
    mundane questions on a huge pile of regulatory texts.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the problem is pretty clear – we are asking the machine to look
    into the regulatory text and provide relevant answers. However, there are instances
    where despite a lot of data being available, analysts don't know what they are
    looking for in the data. We use a method called unsupervised learning to identify
    the issues and anomalies that the data has. Using that, we get to the process
    of understanding the underlying variables that influence the anomalies.
  prefs: []
  type: TYPE_NORMAL
- en: Robotics is another area where there have been significant strides over the
    last 10 years or so. Countries like South Korea have taken robotics to a whole
    new level by deploying about 700 robots per 10000 employees in the manufacturing
    industries. The numbers on the following chart represent 2016 figures. The latest
    figures show that the numbers for South Korea have increased to 710 robots for
    every 10000 employees.
  prefs: []
  type: TYPE_NORMAL
- en: Robotics is used in conducting surgeries, conducting rescue operations that
    are potentially harmful to humans, customer services in banks, logistics, construction
    and even agriculture. Several of these uses are in prototype/pilot stages, but
    are showing promising signs. Industrial applications for robots are starting to
    gain clarity, especially in areas where there are repetitive and mechanical tasks.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, low-skill, high-frequency, mundane jobs will be taken over by machines.
    In the asset management industry, AI is used to make portfolio management decisions
    as the machine can go through millions of data points to arrive at a decision
    much better than a human brain can.
  prefs: []
  type: TYPE_NORMAL
- en: '![Infographic: The Countries With The Highest Density Of Robot Workers  | Statista](img/B13910_08_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Countries with the highest density of robot workers in 2016'
  prefs: []
  type: TYPE_NORMAL
- en: Applications of AI in today's world are unlimited. Every day new avenues and
    real-world opportunities open up for AI. The availability of data has made the
    AI boom possible but has also opened up a whole new can of worms around data privacy,
    data ownership, and data security. With centralized monopoly of consumer data,
    it is often unclear how our data is being used, shared, and monetized. This is
    where a technology like Blockchain could help.
  prefs: []
  type: TYPE_NORMAL
- en: Blockchain
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we briefly touched upon earlier, the Blockchain framework has several properties
    that make it apt to solve some of the data ownership, security, and privacy challenges.
    In today's mostly non-quantum technology landscape, Blockchain also provides data
    security better than centralized data management systems. At the same time, Blockchain
    has limitations that might affect mainstream adoption if not addressed. The history
    and the technology architecture of Blockchain (the Bitcoin Blockchain) was discussed
    in *Chapter 1*, *Introduction to Quantum Computing and Blockchain*.
  prefs: []
  type: TYPE_NORMAL
- en: There are several properties of Blockchain that allow its application across
    multiple industries. However, keeping our focus upon the topic of the data economy,
    let us see how Blockchain and its capabilities joined the party at the perfect
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Decentralization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Decentralization has been the magic mantra of millions of Blockchain believers
    across the world as the technology has gained in popularity over the years. Thanks
    to the scalability trilemma that we discussed earlier in this book, decentralization
    often seems to be an obstacle to achieving commercial scale. Where scalability
    has been achieved by Blockchain, decentralization has often been traded off, making
    it an elusive utopian idea that we all want the world to move towards.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, decentralization does have its advantages. Over the years, we have
    all gotten used to client-servers systems, where most of the data is stored on
    the server. The challenges with this architecture are that:'
  prefs: []
  type: TYPE_NORMAL
- en: The server that holds most of the data is an easy target for cyber criminals.
    Hacking a centralized system to get hold of critical information is easy. There have
    been several instances where banks have been hacked and millions of clients' data
    was lost.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the centralized entity ceases to exist, data owned by customers is often
    lost. If Facebook filed for bankruptcy and ceased operations, the entire dataset
    of 2.3 billion users worldwide could be lost.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a decentralized system, a version of data where consensus has been achieved
    is stored across all nodes on the Blockchain. So, bringing down a node in the
    Blockchain will not mean data loss.
  prefs: []
  type: TYPE_NORMAL
- en: While decentralization protects against data loss, it can also ensure that data
    ownership is not centralized. It is starting to become increasingly important
    for every consumer to manage their data, economic and social identity. Management
    of identity cannot be centralized with one firm for the reasons mentioned before
    as disadvantages of client-server systems. The mechanism of managing identities
    within a decentralized network is called self-sovereign identity management.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to the Blockchain framework, the idea of self-sovereign identity is starting
    to look less elusive than it once was. In a day and age where data is considered
    the new oil, and attention (in the media and social media) is considered the new
    gold, identity must be owned and managed by every individual. If I had a profile
    on Facebook for 10 years, I would need to have complete transparency on how Facebook
    was using my data and monetizing it. Any unapproved usage or selling of customer's
    data can no longer be tolerated.
  prefs: []
  type: TYPE_NORMAL
- en: Before delving further into decentralized traceability that helped with managing
    self-sovereign identity, let us look at the features that prevent cyber-attacks
    on the Blockchain system itself.
  prefs: []
  type: TYPE_NORMAL
- en: Immutability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a system where every block generated uses the hash of the previous block,
    anyone looking to create a false transaction on the Blockchain needs to brute-force
    through the entire chain of blocks. Another logical way of achieving consensus
    on a counterfeit transaction in a Blockchain is to gain control of 51% of the
    nodes. This happens in a Blockchain that has lost popularity. In such a network,
    someone could take over the network to get to 51% control of the network.
  prefs: []
  type: TYPE_NORMAL
- en: There are other ways in which Blockchains can be hacked, like the DAO hack that
    resulted in the hard fork of Ethereum and the birth of Ethereum Classic. However,
    those issues occur when the framework's logic is fundamentally vulnerable.
  prefs: []
  type: TYPE_NORMAL
- en: If such vulnerabilities are forgotten for a minute, Blockchain as it stands
    today acts as an immutable network. Once a transaction is created, it becomes
    very hard for someone to hack and change. While immutability is certainly a desirable
    Blockchain property, it is used in contexts where traceability is needed too.
  prefs: []
  type: TYPE_NORMAL
- en: Traceability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is not hard to build traceability and auditability in traditional database
    management systems. However, when traceability is clubbed with other features
    of Blockchain it makes it decentralized-immutable-traceability, and that is special.
    There are several applications of this property of Blockchain in managing intellectual property
    in a data-intensive world. It also allows you to keep track of how your data is
    being used by third parties, and where relevant, for you to be paid for that as
    a customer.
  prefs: []
  type: TYPE_NORMAL
- en: A few weeks ago, I was talking to a Blockchain architect, and we were discussing
    the user journeys many sites offer, where we had to enter a username and password
    to use their services. He was insistent that the world needed to move on to solutions
    where a customer's digital identity was not stored at an application level. Rather,
    it should be stored at a protocol level. And every time a customer's identity
    needed to be checked, applications could tap into this protocol.
  prefs: []
  type: TYPE_NORMAL
- en: This means that applications like Facebook and Twitter wouldn't necessarily
    be the central holders of an individual's digital identity. Identities would have
    to be ideally managed by a decentralized network of governments. However, when
    the network is managed by a few governments, it is considered centralized and
    as the antithesis of Blockchain. The point here, however, is not the degree of
    decentralization. It is more the fact that identities will have to be managed
    at a more fundamental level.
  prefs: []
  type: TYPE_NORMAL
- en: As identities are managed, so will data owned by individuals be managed. And
    more, users' data will be attributed to them, and they will be informed of any
    money a firm made by using their data. It is the user's decision to choose providers
    who can use their data to make money. For example, an individual may be happy
    for their data to be used (anonymously at an aggregated level) to help make lending
    decisions in banks, but they may not be OK with a big Wall Street bank using it to
    cross-sell products to more customers.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, a user may be OK with their data being used by firms who have
    a low carbon footprint, but when a mining, oil, or gas company wants to use their
    data to make any strategic/commercial decisions, they would want them to pay a
    slice of their earnings from the decision into an environmental charity.
  prefs: []
  type: TYPE_NORMAL
- en: It is not just enough to create an ecosystem that allows data creation, sharing,
    and monetization. It is essential to build the governance and controls around
    it to enable careful use of data. In a world where cyber-attacks will soon be
    used by nation states to wage war against each other, these controls will decide
    the winners from the losers. Countries could stop spending time and money on nuclear
    warheads and start spending more time and energy on protecting the data of their
    citizens using technologies such as Blockchain.
  prefs: []
  type: TYPE_NORMAL
- en: As we go through technologies that are fundamental to the data era, one that
    has stood out is quantum computing. It is still early days for the field, but
    the possibilities are promising.
  prefs: []
  type: TYPE_NORMAL
- en: Quantum computing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a sequence of technology innovations that have made the data economy possible,
    quantum computing is perhaps the cherry on top. We have touched upon various aspects
    of quantum computing that made it such a revolutionary technology paradigm. On
    a practical basis quantum helps us solve some key problems that weren't possible
    before. Many of these practical problems are covered through interviews in this
    book. With quantum computing, AI gets to run on steroids, Blockchain gets a new
    facelift (perhaps after a painful surgery), and big data management and utilization
    could go through a major rethink.
  prefs: []
  type: TYPE_NORMAL
- en: Cybersecurity would look very different when inherent quantum properties like
    entanglement is used to transfer information over large distances. Businesses
    would be able to make real-time data-driven decisions, with higher degrees of
    confidence. In essence, thanks to emerging technologies, we should be able to
    make the most of the data we have created.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every few years, we see new technology trends emerge. No major technology since
    the rise of the internet has managed to thrive without enriching the data economy.
    Be it AI, Big data, Cloud computing, Blockchain, the IoT, 5G, or quantum computing,
    they all interact with the data economy and contribute to it. Some of them have
    more use cases at the Application Layer, some of them at the Protocol Layer, and
    some of them at the Physical/infrastructure Layer. Irrespective of that, they
    have all been disruptive at scale.
  prefs: []
  type: TYPE_NORMAL
- en: The internet laid the foundations of these exciting few years of data innovation.
    Social media built on them. Once we had data created through social media, it
    was all about making the most of it using emerging technologies. Some of these
    technology paradigms had been around even before the advent of the internet and
    social media. But the availability of rich, contextual user data helped innovators
    refine their approach in using and further developing these technologies.
  prefs: []
  type: TYPE_NORMAL
- en: The connectivity offered by the internet allowed for new economic models to
    be created. A connected user base, the network effect, and the engagement that
    was created offered rich data. Businesses thrived in making the most of this data,
    while offering their services free of cost. Value was created digitally using
    Blockchain.
  prefs: []
  type: TYPE_NORMAL
- en: A small network grew into an ecosystem, and a digital economy was created. All
    this happened over the last 15 years at a staggering pace. The question that comes
    up is, can quantum computing enrich this wave of innovation?
  prefs: []
  type: TYPE_NORMAL
- en: In the next few chapters, we will study the potential applications of quantum
    computing and Blockchain across several industries.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[http://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/](http://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[http://jmc.stanford.edu/artificial-intelligence/what-is-ai/branches-of-ai.html](http://jmc.stanford.edu/artificial-intelligence/what-is-ai/branches-of-ai.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://medium.com/@chethankumargn/artificial-intelligence-definition-types-examples-technologies-962ea75c7b9b](mailto:https://medium.com/@chethankumargn/artificial-intelligence-definition-types-examples-technologies-962ea75c7b9b)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
